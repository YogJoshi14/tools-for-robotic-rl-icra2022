<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Tutorial: Tools for Robotic Reinforcement Learning | ICRA 2022</title>
    <link rel="stylesheet" href="https://bulma.io/vendor/fontawesome-free-5.15.2-web/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css">
  </head>
  <body>

    <section class="hero is-light is-medium">
      <!-- Hero head: will stick at the top -->
      <div class="hero-head">
        <nav class="navbar">
          <div class="container">
            <div class="navbar-brand">
              <a class="navbar-item" href="https://www.icra2022.org/">
                <img src="https://www.icra2022.org/sites/default/themes/icra2022/resources/img/logos/title-conf.svg"
                     alt="Logo"
                     width="300px" style="max-height:400px">
              </a>
              <!-- <span class="navbar-burger" data-target="navbarMenuHeroA">
                <span></span>
                <span></span>
                <span></span>
              </span> -->
            </div>
            <div id="navbarMenuHeroA" class="navbar-menu">
              <div class="navbar-end">
                <a class="navbar-item" href="#goals">
                  Goals
                </a>
                <a class="navbar-item" href="#schedule">
                  Schedule
                </a>
                <!-- <a class="navbar-item" href="#notebooks">
                  Notebooks
                </a> -->
                <a class="navbar-item" href="#speakers">
                  Speakers
                </a>
                <a class="navbar-item" href="#organizers">
                  Organizers
                </a>
                <span class="navbar-item">
                  <a class="button is-light is-inverted" href="https://github.com/araffin/tools-for-robotic-rl-icra2022" target="_blank">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Github Repo</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </nav>
      </div>

      <!-- Hero content: will be in the middle -->
      <div class="hero-body">
        <div class="container has-text-centered">
          <h1 class="title">
            Tutorial: Tools for Robotic Reinforcement Learning
          </h1>
          <p class="subtitle">
            Hands-on RL for Robotics with
            <a href="https://github.com/eager-dev/eagerx" target="_blank">EAGERx</a>
            and
            <a href="https://github.com/DLR-RM/stable-baselines3" target="_blank">Stable-Baselines3</a>
          </p>
        </div>
        <div class="container has-text-centered">
          <h3>ICRA 2022, 8:30 AM - 5:20 PM (UTC−4), May 23, 2022 Philadelphia (PA), USA - Room 115A</h3>
        </div>
      </div>

      <!-- Hero footer: will stick at the bottom -->
      <!-- <div class="hero-foot">
        <nav class="tabs">
          <div class="container">
            <ul>
              <li class="is-active"><a>Overview</a></li>
              <li><a>Modifiers</a></li>
              <li><a>Grid</a></li>
              <li><a>Elements</a></li>
              <li><a>Components</a></li>
              <li><a>Layout</a></li>
            </ul>
          </div>
        </nav>
      </div> -->
    </section>

    <div class="container is-max-desktop">

      <section class="section has-text-centered">
        <h2 class="title">Motivation</h2>
        <h3 class="subtitle">
          Reinforcement learning (RL) methods have received much attention due to impressive results in many robotic applications.
          While RL promises learning-based control of near-optimal behaviors in theory, successful learning can elude practitioners due to various implementation challenges.
          Even if the best-suited learning method was selected, learning performance can nonetheless disappoint due to badly chosen hyper-parameters or an unreliable implementation of the algorithm.
          Furthermore, a learning task can be made unnecessarily hard by incorrect specifications.<br>

          This full-day tutorial points-out these practical pitfalls and introduces the audience to the tools for robotic RL that will aid roboticists in successfully solving robotic learning tasks, both in simulation and the real-world.
        </h3>
      </section>

      <section class="section has-text-centered">
        <h2 class="title" id="goals">Goals</h2>
        <h3 class="subtitle">
          We will cover the use of
          <a href="https://github.com/eager-dev/eagerx" target="_blank">Engine Agnostic Gym Environment for Robotics (EAGERx)</a>
          to define and create tasks that work both in simulation and on a real robot, and then learn to use the
          <a href="https://github.com/DLR-RM/stable-baselines3" target="_blank">Stable-Baselines3 (SB3)</a>
          library to solve it with SOTA algorithms, following best practices. <br>
          This tutorial will cover: creating tasks in EAGERx, basic usage of SB3, automatic hyperparameter optimization and managing RL experiments.
        </h3>
      </section>

      <section class="section has-text-centered">
        <h2 class="title">Requirements</h2>
        <h3 class="subtitle">
          Basic knowledge of reinforcement learning and python programming is required.
        </h3>
      </section>

      <section class="section has-text-centered">
        <h2 class="title">Registration</h2>
        <h3 class="subtitle">
          <a href="https://web.cvent.com/event/90e34627-dcf1-4b72-86c9-a0ed745baad4/summary" target="_blank">Register for ICRA 2022 (Free for virtual registration)</a>
        </h3>
      </section>
      <section class="section has-text-centered">
        <h2 class="title">Discord server</h2>
        <h3 class="subtitle">
          <a href="https://discord.gg/zYq82HZy" target="_blank">Join the Discord server</a>
        </h3>
      </section>

      <section class="section">
        <h2 class="title has-text-centered" id="schedule">Schedule</h2>
        <h3 class="subtitle has-text-centered">
          May 23, 8:30 AM - 5:20 PM (UTC−4), Room 115A
        </h3>
        <table class="table is-striped is-fullwidth is-hoverable is-bordered">
           <thead>
              <tr>
                 <th>Time</th>
                 <th>Talk</th>
                 <th>Comments</th>
              </tr>
           </thead>
           <tbody>
              <tr>
                 <td>8:30-8:35</td>
                 <td>Introduction</td>
                 <td></td>
              </tr>
              <tr>
                 <td>8:35-9:45</td>
                 <td>
                   <a href="https://araffin.github.io/slides/icra22-gym-sb3-quickstart/">
                     Getting Started with Gym and RL in practice
                   </a>
                 </td>
                 <td>Presenter: Antonin Raffin</td>
              </tr>
              <tr>
                 <td>9:30-10:30</td>
                 <td>Accelerating physics simulators for Robotics Reinforcement Learning</td>
                 <td>Invited Speaker: Erwin Coumans</td>
              </tr>
              <tr>
                 <td>10:45-11:15</td>
                 <td>
                   <a
                      href="https://colab.research.google.com/github/araffin/tools-for-robotic-rl-icra2022/blob/main/notebooks/icra_hands_on_sb3.ipynb">
                   Hands-on Session with Gym and SB3
                  </a>
                 </td>
                 <td>
                   <a
                      href="https://colab.research.google.com/github/araffin/tools-for-robotic-rl-icra2022/blob/main/notebooks/icra_hands_on_sb3.ipynb">
                   with colab notebooks
                  </a>
                 </td>
              </tr>
              <tr>
                 <td>11:15-11:25</td>
                 <td>Break</td>
                 <td></td>
              </tr>
              <tr>
                 <td>11:25-11:55</td>
                 <td>Getting Started with EAGERx</td>
                 <td>Presenter: Jelle Luijkx </td>
              </tr>
              <tr>
                 <td>11:55-12:30</td>
                 <td>
                   <a
                     href="https://colab.research.google.com/github/eager-dev/eagerx_tutorials/blob/master/tutorials/icra/getting_started.ipynb">
                     Hands-on Session with EAGERx
                   </a>
                 </td>
                 <td>
                   <a
                     href="https://colab.research.google.com/github/eager-dev/eagerx_tutorials/blob/master/tutorials/icra/getting_started.ipynb">
                     with colab notebooks
                   </a>
                </td>
              </tr>
              <tr>
                 <td>12:30-13:30</td>
                 <td>Lunch Break</td>
                 <td></td>
              </tr>
              <tr>
                <td>13:30-14:30</td>
                <td>safe-control-gym: a Unified Benchmark Suite for Safe Learning-based Control and Reinforcement Learning</td>
                <td>Invited Speaker: Angela Schoellig</td>
              </tr>
              <tr>
                 <td>14:30-15:15</td>
                 <td>
                   <a href="https://araffin.github.io/slides/icra22-hyperparam-opt/">
                    Automatic Hyperparameter Optimization
                   </a>
                 </td>
                 <td>Presenter: Antonin Raffin</td>
              </tr>
              <tr>
                 <td>15:15-16:00</td>
                 <td>
                   <a
                     href="https://colab.research.google.com/github/araffin/tools-for-robotic-rl-icra2022/blob/main/notebooks/optuna_lab.ipynb">
                     Hyperparameter Tuning with Optuna
                   </a>
                 </td>
                 <td>
                   <a
                     href="https://colab.research.google.com/github/araffin/tools-for-robotic-rl-icra2022/blob/main/notebooks/optuna_lab.ipynb">
                     with colab notebooks
                   </a>
                 </td>
              </tr>
              <tr>
                 <td>16:00-16:15</td>
                 <td>Break</td>
                 <td></td>
              </tr>
              <tr>
                 <td>16:15-17:15</td>
                 <td>
                   <a
                     href="https://colab.research.google.com/github/eager-dev/eagerx_tutorials/blob/master/tutorials/icra/advanced_usage.ipynb">
                     EAGERx Advanced usage
                   </a>
                 </td>
                 <td>
                   <a
                     href="https://colab.research.google.com/github/eager-dev/eagerx_tutorials/blob/master/tutorials/icra/advanced_usage.ipynb">
                     with colab notebooks
                   </a>
                </td>
              </tr>
              <tr>
                 <td>17:15-17:20</td>
                 <td>Closing remarks</td>
                 <td></td>
              </tr>
           </tbody>
        </table>

      </section>

      <!-- <section class="section">
        <h2 class="title has-text-centered" id="notebooks">Notebooks</h2>

        <h3 class="title has-text-centered">Stable-Baselines3 (SB3)</h3>
        <ol>
          <li>
            <a
              href="https://colab.research.google.com/github/araffin/tools-for-robotic-rl-icra2022/blob/main/notebooks/icra_hands_on_sb3.ipynb">
              Gym/Stable
              Baselines3 Getting Started
            </a>
          </li>
          <li>
            <a
              href="https://colab.research.google.com/github/araffin/tools-for-robotic-rl-icra2022/blob/main/notebooks/optuna_lab.ipynb">
              Hyperparameter
              tuning with Optuna
            </a>
          </li>
        </ol> -->

      </section>

      <section class="section">
        <h2 class="title has-text-centered" id="speakers">Speakers</h2>

        <article class="media">
          <figure class="media-left">
            <p class="image is-128x128">
              <img src="https://avatars.githubusercontent.com/u/725468?v=4">
            </p>
          </figure>
          <div class="media-content">
            <div class="content">
              <p>
                <strong>Erwin Coumans</strong>
                <small>
                  <a href="https://twitter.com/erwincoumans">
                    @erwincoumans
                  </a>
                </small>

                <br>
                Erwin Coumans is creator of the Bullet physics engine,
                former member of the Google Brain team,
                and now works in the NVIDIA Omniverse team.
                His interests include real-time physics simulation research and development,
                 with a focus on robotics and machine learning.
              </p>
            </div>
          </div>
        </article>
        <article class="media">
          <figure class="media-left">
            <p class="image is-128x128">
              <img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=QMfeRz0AAAAJ&citpid=4">
            </p>
          </figure>
          <div class="media-content">
            <div class="content">
              <p>
                <strong>Angela Schoellig</strong>
                <small>
                  <a href="https://twitter.com/angelaschoellig">
                    @angelaschoellig
                  </a>
                </small>

                <br>
                 Angela Schoellig is an Associate Professor at the University of Toronto Institute for Aerospace Studies and a Faculty Member of the Vector Institute for Artificial Intelligence.
                 She conducts research at the intersection of robotics, controls, and machine learning. Her goal is to enhance the performance, safety, and autonomy of robots by enabling them to learn from past experiments and from each other.
              </p>
            </div>
          </div>
        </article>
      </section>

      <section class="section">
        <h2 class="title has-text-centered" id="organizers">Organizers</h2>
        <article class="media">
          <figure class="media-left">
            <p class="image is-128x128">
              <img src="https://media-exp1.licdn.com/dms/image/C5603AQHnL2olLCKDoQ/profile-displayphoto-shrink_200_200/0/1605105302591?e=2147483647&v=beta&t=QGBBEf-qHBlHSIiobOhM5CZIiSBt4WYJsmaO_fD1FG0">
            </p>
          </figure>
          <div class="media-content">
            <div class="content">
              <p>
                <strong>Jelle Luijkx</strong>

                <small>
                  <a href="https://github.com/jelledouwe">
                    @jelledouwe
                  </a>
                </small>

                <br>
                Jelle is a PhD candidate at the Cognitive Robotics department of the Delft University of Technology.
                He is working on deep learning tools for robot control within the OpenDR project and is co-creator of the Engine Agnostic Gym Environment for Robotics (EAGERx) toolkit.
              </p>
            </div>
          </div>
        </article>
        <article class="media">
          <figure class="media-left">
            <p class="image is-128x128">
              <img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=rLHzGRMAAAAJ&citpid=1">
            </p>
          </figure>
          <div class="media-content">
            <div class="content">
              <p>
                <strong>Bas Van der Heijden</strong>

                <small>
                  <a href="https://github.com/bheijden">
                    @bheijden
                  </a>
                </small>

                <br>
                Bas is a PhD candidate at TU Delft working on robotics and reinforcement learning.
                He is co-creator of the Engine Agnostic Gym Environment for Robotics (EAGERx) toolkit.
              </p>
            </div>
          </div>
        </article>
        <article class="media">
          <figure class="media-left">
            <p class="image is-128x128">
              <img src="https://araffin.github.io/authors/admin/avatar_hu33d8f2710ea4928d295bd08cdc05f6eb_60040_270x270_fill_q90_lanczos_center.jpg">
            </p>
          </figure>
          <div class="media-content">
            <div class="content">
              <p>
                <strong>Antonin Raffin</strong>
                <small>
                  <a href="https://twitter.com/araffin2">
                    @araffin2
                  </a>
                </small>
                <br>
                Antonin Raffin is a Research Engineer in Robotics and Machine Learning at the German Aerospace Center (DLR).

                He was previously working on state representation learning in the ENSTA robotics lab (U2IS) where he co-created the Stable-Baselines library with Ashley Hill. His research focus is now on applying reinforcement learning directly on real robots, for which he continues to maintain the Stable-Baselines3 library.

              </p>
            </div>
          </div>
        </article>

        <article class="media">
          <figure class="media-left">
            <p class="image is-128x128">
              <img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=XOWZzUcAAAAJ&citpid=8">
            </p>
          </figure>
          <div class="media-content">
            <div class="content">
              <p>
                <strong>Jens Kober </strong>

                <br>
                Jens Kober is an associate professor at the Cognitive
                Robotics department, 3mE, TU Delft, Netherlands. He worked as a
                postdoctoral scholar jointly at the CoR-Lab, Bielefeld University,
                Germany and at the Honda Research Institute Europe, Germany. He
                graduated in 2012 with a PhD Degree in Engineering from TU Darmstadt and
                the MPI for Intelligent Systems. For his research he received the
                annually awarded Georges Giralt PhD Award for the best PhD thesis in
                robotics in Europe, the 2018 IEEE RAS Early Academic Career Award, and
                has received an ERC Starting grant. His research interests include motor
                skill learning, (deep) reinforcement learning, imitation learning,
                interactive learning, and machine learning for control.

              </p>
            </div>
          </div>
        </article>

      </section>

      <section class="section has-text-centered">
        <h2 class="title">Acknowledgements</h2>
        <h3 class="subtitle">
          The tutorial is supported by the EU H2020 projects
          <i>
            <a href="https://www.veridream.eu/">
              VERtical Innovation in the Domain of Robotics Enabled by Artificial intelligence Methods
            </a>
          </i>
          and
          <i>
            <a href="https://opendr.eu/">OpenDR</a>
          </i>.
        </h3>
        <h3 class="subtitle">
          The tutorial is also supported by the
          <a href="https://www.ieee-ras.org/robot-learning">
            IEEE RAS Technical Committee on Robot Learning
          </a>
          .
        </h3>
      </section>

    </div>

    <footer class="footer">
    <div class="content has-text-centered">
      <p>
        Template made by <a href="https://araffin.github.io/">Antonin Raffin</a>
        based on <i>Bulma</i>. The source code is licensed
        <a href="http://opensource.org/licenses/mit-license.php">MIT</a>. The website content
        is licensed <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY NC SA 4.0</a>.
      </p>
    </div>
  </footer>

  </body>
</html>
